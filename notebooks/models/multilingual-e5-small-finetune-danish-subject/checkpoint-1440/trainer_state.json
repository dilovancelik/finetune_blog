{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 1440,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0020833333333333333,
      "grad_norm": 2.191904067993164,
      "learning_rate": 1.3888888888888888e-07,
      "loss": 2.5221,
      "step": 1
    },
    {
      "epoch": 0.052083333333333336,
      "grad_norm": 2.4048306941986084,
      "learning_rate": 3.4722222222222224e-06,
      "loss": 2.2464,
      "step": 25
    },
    {
      "epoch": 0.10416666666666667,
      "grad_norm": 2.0481317043304443,
      "learning_rate": 6.944444444444445e-06,
      "loss": 2.1919,
      "step": 50
    },
    {
      "epoch": 0.15625,
      "grad_norm": 2.266857385635376,
      "learning_rate": 1.0416666666666668e-05,
      "loss": 2.1619,
      "step": 75
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 2.904446840286255,
      "learning_rate": 1.388888888888889e-05,
      "loss": 2.0809,
      "step": 100
    },
    {
      "epoch": 0.20833333333333334,
      "eval_loss": 1.8925727605819702,
      "eval_runtime": 46.5512,
      "eval_samples_per_second": 20.622,
      "eval_steps_per_second": 2.578,
      "step": 100
    },
    {
      "epoch": 0.2604166666666667,
      "grad_norm": 3.725435256958008,
      "learning_rate": 1.7361111111111114e-05,
      "loss": 1.8804,
      "step": 125
    },
    {
      "epoch": 0.3125,
      "grad_norm": 4.605605602264404,
      "learning_rate": 1.990740740740741e-05,
      "loss": 1.6553,
      "step": 150
    },
    {
      "epoch": 0.3645833333333333,
      "grad_norm": 4.592827320098877,
      "learning_rate": 1.9521604938271607e-05,
      "loss": 1.1717,
      "step": 175
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 4.746060371398926,
      "learning_rate": 1.9135802469135804e-05,
      "loss": 1.095,
      "step": 200
    },
    {
      "epoch": 0.4166666666666667,
      "eval_loss": 0.9134344458580017,
      "eval_runtime": 24.4671,
      "eval_samples_per_second": 39.236,
      "eval_steps_per_second": 4.905,
      "step": 200
    },
    {
      "epoch": 0.46875,
      "grad_norm": 5.914793968200684,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.9379,
      "step": 225
    },
    {
      "epoch": 0.5208333333333334,
      "grad_norm": 8.525018692016602,
      "learning_rate": 1.83641975308642e-05,
      "loss": 0.9077,
      "step": 250
    },
    {
      "epoch": 0.5729166666666666,
      "grad_norm": 7.075133323669434,
      "learning_rate": 1.7978395061728397e-05,
      "loss": 0.8905,
      "step": 275
    },
    {
      "epoch": 0.625,
      "grad_norm": 7.213322639465332,
      "learning_rate": 1.7592592592592595e-05,
      "loss": 0.8633,
      "step": 300
    },
    {
      "epoch": 0.625,
      "eval_loss": 0.8229990601539612,
      "eval_runtime": 22.8532,
      "eval_samples_per_second": 42.007,
      "eval_steps_per_second": 5.251,
      "step": 300
    },
    {
      "epoch": 0.6770833333333334,
      "grad_norm": 5.837014198303223,
      "learning_rate": 1.7206790123456792e-05,
      "loss": 0.94,
      "step": 325
    },
    {
      "epoch": 0.7291666666666666,
      "grad_norm": 9.466167449951172,
      "learning_rate": 1.682098765432099e-05,
      "loss": 0.8487,
      "step": 350
    },
    {
      "epoch": 0.78125,
      "grad_norm": 7.2786993980407715,
      "learning_rate": 1.6435185185185187e-05,
      "loss": 0.8346,
      "step": 375
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 8.929422378540039,
      "learning_rate": 1.6049382716049385e-05,
      "loss": 0.8212,
      "step": 400
    },
    {
      "epoch": 0.8333333333333334,
      "eval_loss": 0.7733975648880005,
      "eval_runtime": 22.4692,
      "eval_samples_per_second": 42.725,
      "eval_steps_per_second": 5.341,
      "step": 400
    },
    {
      "epoch": 0.8854166666666666,
      "grad_norm": 7.046673774719238,
      "learning_rate": 1.5663580246913583e-05,
      "loss": 0.7371,
      "step": 425
    },
    {
      "epoch": 0.9375,
      "grad_norm": 5.639375686645508,
      "learning_rate": 1.5277777777777777e-05,
      "loss": 0.769,
      "step": 450
    },
    {
      "epoch": 0.9895833333333334,
      "grad_norm": 10.980193138122559,
      "learning_rate": 1.4891975308641978e-05,
      "loss": 0.8514,
      "step": 475
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 7.386209964752197,
      "learning_rate": 1.4506172839506174e-05,
      "loss": 0.6988,
      "step": 500
    },
    {
      "epoch": 1.0416666666666667,
      "eval_loss": 0.733709990978241,
      "eval_runtime": 22.8605,
      "eval_samples_per_second": 41.994,
      "eval_steps_per_second": 5.249,
      "step": 500
    },
    {
      "epoch": 1.09375,
      "grad_norm": 12.966715812683105,
      "learning_rate": 1.4120370370370371e-05,
      "loss": 0.7052,
      "step": 525
    },
    {
      "epoch": 1.1458333333333333,
      "grad_norm": 12.319723129272461,
      "learning_rate": 1.373456790123457e-05,
      "loss": 0.7061,
      "step": 550
    },
    {
      "epoch": 1.1979166666666667,
      "grad_norm": 14.18096923828125,
      "learning_rate": 1.3348765432098767e-05,
      "loss": 0.7736,
      "step": 575
    },
    {
      "epoch": 1.25,
      "grad_norm": 14.476485252380371,
      "learning_rate": 1.2962962962962964e-05,
      "loss": 0.7186,
      "step": 600
    },
    {
      "epoch": 1.25,
      "eval_loss": 0.7179242968559265,
      "eval_runtime": 22.9152,
      "eval_samples_per_second": 41.894,
      "eval_steps_per_second": 5.237,
      "step": 600
    },
    {
      "epoch": 1.3020833333333333,
      "grad_norm": 10.586742401123047,
      "learning_rate": 1.257716049382716e-05,
      "loss": 0.7453,
      "step": 625
    },
    {
      "epoch": 1.3541666666666667,
      "grad_norm": 9.043983459472656,
      "learning_rate": 1.219135802469136e-05,
      "loss": 0.6801,
      "step": 650
    },
    {
      "epoch": 1.40625,
      "grad_norm": 9.923300743103027,
      "learning_rate": 1.1805555555555557e-05,
      "loss": 0.6776,
      "step": 675
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 13.17048168182373,
      "learning_rate": 1.1419753086419753e-05,
      "loss": 0.8244,
      "step": 700
    },
    {
      "epoch": 1.4583333333333333,
      "eval_loss": 0.7016851305961609,
      "eval_runtime": 22.9249,
      "eval_samples_per_second": 41.876,
      "eval_steps_per_second": 5.234,
      "step": 700
    },
    {
      "epoch": 1.5104166666666665,
      "grad_norm": 9.742420196533203,
      "learning_rate": 1.103395061728395e-05,
      "loss": 0.5805,
      "step": 725
    },
    {
      "epoch": 1.5625,
      "grad_norm": 8.136651992797852,
      "learning_rate": 1.064814814814815e-05,
      "loss": 0.834,
      "step": 750
    },
    {
      "epoch": 1.6145833333333335,
      "grad_norm": 7.320347785949707,
      "learning_rate": 1.0262345679012347e-05,
      "loss": 0.7908,
      "step": 775
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 8.509465217590332,
      "learning_rate": 9.876543209876543e-06,
      "loss": 0.798,
      "step": 800
    },
    {
      "epoch": 1.6666666666666665,
      "eval_loss": 0.6918795108795166,
      "eval_runtime": 23.095,
      "eval_samples_per_second": 41.567,
      "eval_steps_per_second": 5.196,
      "step": 800
    },
    {
      "epoch": 1.71875,
      "grad_norm": 7.196074485778809,
      "learning_rate": 9.490740740740741e-06,
      "loss": 0.6726,
      "step": 825
    },
    {
      "epoch": 1.7708333333333335,
      "grad_norm": 7.471927642822266,
      "learning_rate": 9.10493827160494e-06,
      "loss": 0.8127,
      "step": 850
    },
    {
      "epoch": 1.8229166666666665,
      "grad_norm": 10.325223922729492,
      "learning_rate": 8.719135802469136e-06,
      "loss": 0.6581,
      "step": 875
    },
    {
      "epoch": 1.875,
      "grad_norm": 13.34957218170166,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.6338,
      "step": 900
    },
    {
      "epoch": 1.875,
      "eval_loss": 0.6871259212493896,
      "eval_runtime": 25.6887,
      "eval_samples_per_second": 37.371,
      "eval_steps_per_second": 4.671,
      "step": 900
    },
    {
      "epoch": 1.9270833333333335,
      "grad_norm": 4.931265354156494,
      "learning_rate": 7.947530864197531e-06,
      "loss": 0.7073,
      "step": 925
    },
    {
      "epoch": 1.9791666666666665,
      "grad_norm": 14.914851188659668,
      "learning_rate": 7.561728395061729e-06,
      "loss": 0.658,
      "step": 950
    },
    {
      "epoch": 2.03125,
      "grad_norm": 10.67338752746582,
      "learning_rate": 7.1759259259259266e-06,
      "loss": 0.6645,
      "step": 975
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 9.443819999694824,
      "learning_rate": 6.790123456790124e-06,
      "loss": 0.7319,
      "step": 1000
    },
    {
      "epoch": 2.0833333333333335,
      "eval_loss": 0.6859115362167358,
      "eval_runtime": 23.8768,
      "eval_samples_per_second": 40.206,
      "eval_steps_per_second": 5.026,
      "step": 1000
    },
    {
      "epoch": 2.1354166666666665,
      "grad_norm": 16.378782272338867,
      "learning_rate": 6.404320987654321e-06,
      "loss": 0.6433,
      "step": 1025
    },
    {
      "epoch": 2.1875,
      "grad_norm": 11.296469688415527,
      "learning_rate": 6.018518518518519e-06,
      "loss": 0.6124,
      "step": 1050
    },
    {
      "epoch": 2.2395833333333335,
      "grad_norm": 11.586078643798828,
      "learning_rate": 5.632716049382716e-06,
      "loss": 0.7044,
      "step": 1075
    },
    {
      "epoch": 2.2916666666666665,
      "grad_norm": 6.7321085929870605,
      "learning_rate": 5.246913580246914e-06,
      "loss": 0.6742,
      "step": 1100
    },
    {
      "epoch": 2.2916666666666665,
      "eval_loss": 0.6779245138168335,
      "eval_runtime": 25.6137,
      "eval_samples_per_second": 37.48,
      "eval_steps_per_second": 4.685,
      "step": 1100
    },
    {
      "epoch": 2.34375,
      "grad_norm": 10.522826194763184,
      "learning_rate": 4.861111111111111e-06,
      "loss": 0.7016,
      "step": 1125
    },
    {
      "epoch": 2.3958333333333335,
      "grad_norm": 8.209543228149414,
      "learning_rate": 4.475308641975309e-06,
      "loss": 0.6361,
      "step": 1150
    },
    {
      "epoch": 2.4479166666666665,
      "grad_norm": 10.77342700958252,
      "learning_rate": 4.0895061728395066e-06,
      "loss": 0.6467,
      "step": 1175
    },
    {
      "epoch": 2.5,
      "grad_norm": 10.630361557006836,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 0.6164,
      "step": 1200
    },
    {
      "epoch": 2.5,
      "eval_loss": 0.6755567193031311,
      "eval_runtime": 24.5828,
      "eval_samples_per_second": 39.052,
      "eval_steps_per_second": 4.881,
      "step": 1200
    },
    {
      "epoch": 2.5520833333333335,
      "grad_norm": 9.978835105895996,
      "learning_rate": 3.3179012345679013e-06,
      "loss": 0.8299,
      "step": 1225
    },
    {
      "epoch": 2.6041666666666665,
      "grad_norm": 7.784616470336914,
      "learning_rate": 2.9320987654320994e-06,
      "loss": 0.6434,
      "step": 1250
    },
    {
      "epoch": 2.65625,
      "grad_norm": 14.04677677154541,
      "learning_rate": 2.5462962962962966e-06,
      "loss": 0.7209,
      "step": 1275
    },
    {
      "epoch": 2.7083333333333335,
      "grad_norm": 9.624374389648438,
      "learning_rate": 2.1604938271604937e-06,
      "loss": 0.7759,
      "step": 1300
    },
    {
      "epoch": 2.7083333333333335,
      "eval_loss": 0.6724839806556702,
      "eval_runtime": 24.5626,
      "eval_samples_per_second": 39.084,
      "eval_steps_per_second": 4.885,
      "step": 1300
    },
    {
      "epoch": 2.7604166666666665,
      "grad_norm": 7.244726181030273,
      "learning_rate": 1.7746913580246916e-06,
      "loss": 0.6215,
      "step": 1325
    },
    {
      "epoch": 2.8125,
      "grad_norm": 7.808193206787109,
      "learning_rate": 1.3888888888888892e-06,
      "loss": 0.5715,
      "step": 1350
    },
    {
      "epoch": 2.8645833333333335,
      "grad_norm": 14.153206825256348,
      "learning_rate": 1.0030864197530866e-06,
      "loss": 0.6756,
      "step": 1375
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 11.44605541229248,
      "learning_rate": 6.17283950617284e-07,
      "loss": 0.5999,
      "step": 1400
    },
    {
      "epoch": 2.9166666666666665,
      "eval_loss": 0.6728169918060303,
      "eval_runtime": 23.4047,
      "eval_samples_per_second": 41.017,
      "eval_steps_per_second": 5.127,
      "step": 1400
    },
    {
      "epoch": 2.96875,
      "grad_norm": 9.691278457641602,
      "learning_rate": 2.3148148148148148e-07,
      "loss": 0.5288,
      "step": 1425
    }
  ],
  "logging_steps": 25,
  "max_steps": 1440,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
